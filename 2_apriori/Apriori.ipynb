{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Authors: Fernando Díaz González and Giorgio Ruffa\n",
    "{fdiaz, ruffa}@kth.se\n",
    "\n",
    "ID 2222 Data Mining. Assignment 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import random\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To compute the frequent itemsets we are going to use a support degree of 1% (aprox 1000 transactions). For rule discovery, we will use a confidence of 80%. $k$ is the number of items in a generic itemset, `k_max` is the maximum cardinality of the itemset that we are going to compute. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "support_threshold_percentage = 0.01\n",
    "confidence_threshold = 0.6\n",
    "k_max = 4  # triplets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frequent itemsets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each $k$, we populate a default dictionary using the itemset as the key and a set of transactions ids in which the itemset appears as the value. The transaction id is the line number of the data file.\n",
    "\n",
    "In the following cell we compute the dictionary for $k = 1$, that is, for the singletons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of transactions: 100000\n",
      "Total number of distinct items: 870\n",
      "Support percentage thr 0.01, equivalent to at leat 1000 transactions\n",
      "The item 25 appears in the following transactions (showing 20): [0, 8204, 16397, 17, 57371, 32802, 73766, 81962, 98351, 98356, 73784, 49215, 81999, 32859, 73822, 57440, 73827, 32895, 90239, 16523]...\n"
     ]
    }
   ],
   "source": [
    "data_file = \"./data/T10I4D100K.dat\"\n",
    "\n",
    "k_list = [None] * k_max\n",
    "\n",
    "tot_transactions = 0\n",
    "with open(data_file, 'r') as data_file:\n",
    "    singleton_to_transactions = defaultdict(set)\n",
    "    for transaction_id, transaction in enumerate(data_file):\n",
    "        for item in transaction.strip(\" \\n\").split(\" \"):\n",
    "            singleton_to_transactions[frozenset({item})].add(transaction_id)\n",
    "        tot_transactions += 1\n",
    "    k_list[0] = singleton_to_transactions\n",
    "\n",
    "\n",
    "print(\"Total number of transactions: {}\".format(tot_transactions))\n",
    "print(\"Total number of distinct items: {}\".format(len(k_list[0].keys())))\n",
    "support_threshold = int(support_threshold_percentage * tot_transactions)\n",
    "print(\"Support percentage thr {}, equivalent to at leat {} transactions\".format(\n",
    "    support_threshold_percentage, support_threshold))\n",
    "print(\"The item {} appears in the following transactions (showing 20): {}...\".format(\n",
    "    \"25\", list(k_list[0][frozenset({\"25\"})])[0:20]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this representation, the support is the length of the transaction set.\n",
    "\n",
    "In the following cell we filter the singletons with a support less than the threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remaining singletons: 375\n"
     ]
    }
   ],
   "source": [
    "def filter_and_remove(set_to_transactions, support_threshold):\n",
    "    items_below_threshold = [\n",
    "        item for item, transactions in set_to_transactions.items() if len(transactions) < support_threshold\n",
    "    ]\n",
    "    for item in items_below_threshold:\n",
    "        del(set_to_transactions[item])\n",
    "        \n",
    "filter_and_remove(k_list[0], support_threshold)\n",
    "print(\"Remaining singletons: {}\".format(len(k_list[0].keys())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we iteratively generate and filter the $k$ itemsets for $k = 2,...,k\\_max$. To get the $k$ itemsets we combine the filtered singletons with the $k - 1$ itemsets. Example, to get pairs, we combine singletons with singletons; to get triplets, we combine singletons with pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Computing itemsets of size 2 **\n",
      "** Computing itemsets of size 3 **\n",
      "** Computing itemsets of size 4 **\n"
     ]
    }
   ],
   "source": [
    "for k in range(2, k_max + 1):\n",
    "    print(\"** Computing itemsets of size {} **\".format(k))\n",
    "    singletons = k_list[0]\n",
    "    k_minus_one_itemsets = k_list[k - 2]\n",
    "    k_item_set_to_transactions = defaultdict(set)\n",
    "    for keyA, keyB in itertools.product(singletons.keys(), k_minus_one_itemsets.keys()):\n",
    "        k_item_set = frozenset(keyA.union(keyB))\n",
    "        if len(k_item_set) != k:\n",
    "            continue\n",
    "        common_txs = singletons[keyA].intersection(k_minus_one_itemsets[keyB])\n",
    "        k_item_set_to_transactions[k_item_set] = common_txs\n",
    "    filter_and_remove(k_item_set_to_transactions, support_threshold)\n",
    "    k_list[k - 1] = k_item_set_to_transactions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We print the first 10 itemsets for each $k$ (not ordered by support)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of 1-itemsets with support 1000 = 375\n",
      "Items: frozenset({'25'})                -> Support: 1395\n",
      "Items: frozenset({'52'})                -> Support: 1983\n",
      "Items: frozenset({'240'})               -> Support: 1399\n",
      "Items: frozenset({'274'})               -> Support: 2628\n",
      "Items: frozenset({'368'})               -> Support: 7828\n",
      "Items: frozenset({'448'})               -> Support: 1370\n",
      "Items: frozenset({'538'})               -> Support: 3982\n",
      "Items: frozenset({'561'})               -> Support: 2783\n",
      "Items: frozenset({'630'})               -> Support: 1523\n",
      "Items: frozenset({'687'})               -> Support: 1762\n",
      "Items: frozenset({'775'})               -> Support: 3771\n",
      "Number of 2-itemsets with support 1000 = 9\n",
      "Items: frozenset({'682', '368'})        -> Support: 1193\n",
      "Items: frozenset({'829', '368'})        -> Support: 1194\n",
      "Items: frozenset({'825', '39'})         -> Support: 1187\n",
      "Items: frozenset({'825', '704'})        -> Support: 1102\n",
      "Items: frozenset({'704', '39'})         -> Support: 1107\n",
      "Items: frozenset({'390', '227'})        -> Support: 1049\n",
      "Items: frozenset({'390', '722'})        -> Support: 1042\n",
      "Items: frozenset({'217', '346'})        -> Support: 1336\n",
      "Items: frozenset({'829', '789'})        -> Support: 1194\n",
      "Number of 3-itemsets with support 1000 = 1\n",
      "Items: frozenset({'825', '39', '704'})  -> Support: 1035\n",
      "Number of 4-itemsets with support 1000 = 0\n"
     ]
    }
   ],
   "source": [
    "for idx, k_itemsets in enumerate(k_list):\n",
    "    k = idx + 1\n",
    "    n_itemsets = len(k_itemsets)\n",
    "    print(\"Number of {}-itemsets with support {} = {}\".format(\n",
    "        k, support_threshold, n_itemsets))\n",
    "    for idx, (itemset, transactions) in enumerate(k_itemsets.items()):\n",
    "        print(\"Items: {!s:<32} -> Support: {}\".format(itemset, len(transactions)))\n",
    "        if idx == 10:\n",
    "              break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The obtained result agrees with what reported by [ZHIGANG WANG et al](http://ijssst.info/Vol-17/No-32/paper44.pdf)\n",
    "\n",
    "![frequent-items](frequent-items.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Association rules\n",
    "\n",
    "To find the antecedent and consequent of the rules, we iterate over all the itemsets with $k > 1$, generating all the possible combinations between its elements. For example, given a itemset $S$ like `{\"a\", \"b\", \"c\"}`, we generate the following rules:\n",
    "* `{\"a\"} -> {\"b\", \"c\"}`\n",
    "* `{\"b\"} -> {\"a\", \"c\"}`\n",
    "* `{\"c\"} -> {\"a\", \"b\"}`\n",
    "* `{\"a\"} -> {\"b\", \"c\"}`\n",
    "* `{\"b\", \"c\"} -> {\"a\"}`\n",
    "* `{\"b\", \"a\"} -> {\"c\"}`\n",
    "* `{\"a\", \"c\"} -> {\"b\"}`\n",
    "\n",
    "As you can see, the consequent is the result of the operation $S - antecedent$, where $S$ and $antecedent$ are both sets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_rules(k_list, confidence_threshold=0.5):\n",
    "    rules = []\n",
    "    # Iterate over all itemsets with k > 1 (pairs, triplets ...)\n",
    "    for idx, k_itemsets in enumerate(k_list[1:]):\n",
    "        k = idx + 1\n",
    "        for itemset, transactions in k_itemsets.items():\n",
    "            # This will be the support of the 'consequent' in the rule\n",
    "            itemset_support = len(transactions)\n",
    "            for i in range(len(itemset) - 1):\n",
    "                # Generate antecedents of different sizes (1,...,k),\n",
    "                # where k is the size of the itemset\n",
    "                antecedents = list(itertools.combinations(itemset, i + 1))\n",
    "                for antecedent in antecedents:\n",
    "                    antecedent = frozenset(antecedent)\n",
    "                    consequent = itemset - antecedent\n",
    "                    k_antecedent = len(antecedent)\n",
    "                    k_antecedent_itemsets = k_list[k_antecedent - 1]\n",
    "                    # Find transaction list of antecedent, its length is the support\n",
    "                    antecedent_support = len(k_antecedent_itemsets[antecedent])\n",
    "                    confidence = itemset_support / antecedent_support\n",
    "                    if confidence >= confidence_threshold:\n",
    "                        rules.append((antecedent, consequent, confidence, itemset_support))\n",
    "    return rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5 rules, showing 15\n",
      "frozenset({'704'}) -> frozenset({'825'}) (confidence: 0.6142697881828316)\n",
      "frozenset({'704', '39'}) -> frozenset({'825'}) (confidence: 0.9349593495934959)\n",
      "frozenset({'825', '39'}) -> frozenset({'704'}) (confidence: 0.8719460825610783)\n",
      "frozenset({'704'}) -> frozenset({'825'}) (confidence: 0.6142697881828316)\n",
      "frozenset({'825', '39'}) -> frozenset({'704'}) (confidence: 0.8719460825610783)\n"
     ]
    }
   ],
   "source": [
    "SHOW = 15\n",
    "rules = find_rules(k_list, confidence_threshold)\n",
    "n_rules = len(rules)\n",
    "print(\"Found {} rules, showing {}\".format(n_rules, SHOW))\n",
    "for i in range(min(SHOW, n_rules)):\n",
    "    antecedent, consequent, confidence, _ = random.choice(rules)\n",
    "    print(\"{} -> {} (confidence: {})\".format(antecedent, consequent, confidence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
